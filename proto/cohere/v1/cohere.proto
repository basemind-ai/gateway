syntax = "proto3";

package cohere.v1;

option go_package = "github.com/basemind-ai/monorepo/gen/cohereconnector";

// The CohereService service definition.
service CohereService {
  // Request a regular LLM prompt
  rpc CoherePrompt(CoherePromptRequest) returns (CoherePromptResponse) {}
  // Request a streaming LLM prompt
  rpc CohereStream(CoherePromptRequest) returns (stream CohereStreamResponse) {}
}

// Type of Cohere Model
enum CohereModel {
  // Cohere Model is not specified
  COHERE_MODEL_UNSPECIFIED = 0;
  // Command - the default Cohere model.
  COHERE_MODEL_COMMAND = 1;
  // Command Light - a faster but less accurate version of Command.
  COHERE_MODEL_COMMAND_LIGHT = 2;
  // Command Nightly - a nightly version of Command.
  COHERE_MODEL_COMMAND_NIGHTLY = 3;
  // Command Light Nightly - a nightly version of Command Light.
  COHERE_MODEL_COMMAND_LIGHT_NIGHTLY = 4;
}

// Type of Cohere RAG Connector
enum CohereConnectorType {
  // Cohere Connector is not specified
  COHERE_CONNECTOR_TYPE_UNSPECIFIED = 0;
  // Cohere Connector is a web search.
  COHERE_CONNECTOR_TYPE_WEB_SEARCH = 1;
  // Cohere Connector is a custom ID.
  COHERE_CONNECTOR_TYPE_ID = 2;
}

// Cohere API Request parameters
message CohereModelParameters {
  // see: https://docs.cohere.com/reference/generate

  // Temperature Sampling: Should be a non-negative float (0-5.0) that tunes the degree of randomness in generation.
  // Lower temperatures mean less random generations.
  optional float temperature = 1;
  //Ensures only the top k most likely tokens are considered for generation at each step.
  // Defaults to 0, min value of 0, max value of 500.
  optional uint32 k = 2;
  // Ensures that only the most likely tokens, with total probability mass of p, are considered for generation at each step.
  // If both k and p are enabled, p acts after k.
  optional float p = 3;
  // Used to reduce repetitiveness of generated tokens. The higher the value, the stronger a penalty is applied to
  // previously present tokens, proportional to how many times they have already appeared in the
  // prompt or prior generation.
  optional float frequency_penalty = 4;
  // Defaults to 0.0, min value of 0.0, max value of 1.0. Can be used to reduce repetitiveness of generated tokens.
  // Similar to frequency_penalty, except that this penalty is applied equally to all tokens that have already appeared,
  // regardless of their exact frequencies.
  optional float presence_penalty = 5;

  // The maximum number of tokens the model will generate as part of the response.
  //
  // Note: Setting a low value may
  // result in incomplete generations. This parameter is off by default, and if it's not specified, the model will
  // continue generating until it emits an EOS completion token.
  optional uint32 max_tokens = 6;
}

//  The CoherePromptRequest contains the data that will be sent to the Cohere API.
message CoherePromptRequest {
  // Cohere Model identifier
  CohereModel model = 1;
  // Prompt message
  string message = 2;
  // Cohere API Request parameters
  CohereModelParameters parameters = 3;
}

// The CoherePromptResponse contains the data that is returned from the Cohere API.
message CoherePromptResponse {
  // Prompt Content
  string content = 1;
  // Finish reason, if this is the last message
  string finish_reason = 2;
  // Count of the request tokens, as returned by the Cohere /tokenize endpoint
  uint32 request_tokens_count = 3;
  // Count of the response tokens, as returned by the Cohere /tokenize endpoint
  uint32 response_tokens_count = 4;
}

// The CohereStreamResponse contains the data that is streamed from the Cohere API.
message CohereStreamResponse {
  // Prompt Content
  optional string content = 1;
  // Finish reason, if this is the last message
  optional string finish_reason = 2;
  // Count of the request tokens, as returned by the Cohere /tokenize endpoint
  optional uint32 request_tokens_count = 3;
  // Count of the response tokens, as returned by the Cohere /tokenize endpoint
  optional uint32 response_tokens_count = 4;
}
