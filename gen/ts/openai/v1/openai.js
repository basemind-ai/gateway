// @generated by protobuf-ts 2.9.1 with parameter generate_dependencies,long_type_string,output_javascript_es2020,server_grpc1,force_client_none
// @generated from protobuf file "openai/v1/openai.proto" (package "openai.v1", syntax proto3)
// tslint:disable
// @generated by protobuf-ts 2.9.1 with parameter generate_dependencies,long_type_string,output_javascript_es2020,server_grpc1,force_client_none
// @generated from protobuf file "openai/v1/openai.proto" (package "openai.v1", syntax proto3)
// tslint:disable
import { ServiceType } from "@protobuf-ts/runtime-rpc";
import { WireType } from "@protobuf-ts/runtime";
import { UnknownFieldHandler } from "@protobuf-ts/runtime";
import { reflectionMergePartial } from "@protobuf-ts/runtime";
import { MESSAGE_TYPE } from "@protobuf-ts/runtime";
import { MessageType } from "@protobuf-ts/runtime";
/**
 * Type of OpenAI Model
 *
 * @generated from protobuf enum openai.v1.OpenAIModel
 */
export var OpenAIModel;
(function (OpenAIModel) {
    /**
     * OpenAI Model is not Specified
     *
     * @generated from protobuf enum value: OPEN_AI_MODEL_UNSPECIFIED = 0;
     */
    OpenAIModel[OpenAIModel["OPEN_AI_MODEL_UNSPECIFIED"] = 0] = "OPEN_AI_MODEL_UNSPECIFIED";
    /**
     * OpenAI GPT3.5 Turbo 4K
     *
     * @generated from protobuf enum value: OPEN_AI_MODEL_GPT3_5_TURBO_4K = 1;
     */
    OpenAIModel[OpenAIModel["OPEN_AI_MODEL_GPT3_5_TURBO_4K"] = 1] = "OPEN_AI_MODEL_GPT3_5_TURBO_4K";
    /**
     * OpenAI GPT3.5 Turbo 16K
     *
     * @generated from protobuf enum value: OPEN_AI_MODEL_GPT3_5_TURBO_16K = 2;
     */
    OpenAIModel[OpenAIModel["OPEN_AI_MODEL_GPT3_5_TURBO_16K"] = 2] = "OPEN_AI_MODEL_GPT3_5_TURBO_16K";
    /**
     * OpenAI GPT4 8K
     *
     * @generated from protobuf enum value: OPEN_AI_MODEL_GPT4_8K = 3;
     */
    OpenAIModel[OpenAIModel["OPEN_AI_MODEL_GPT4_8K"] = 3] = "OPEN_AI_MODEL_GPT4_8K";
    /**
     * OpenAI GPT4 32K
     *
     * @generated from protobuf enum value: OPEN_AI_MODEL_GPT4_32K = 4;
     */
    OpenAIModel[OpenAIModel["OPEN_AI_MODEL_GPT4_32K"] = 4] = "OPEN_AI_MODEL_GPT4_32K";
})(OpenAIModel || (OpenAIModel = {}));
/**
 * Type of OpenAI Message
 *
 * @generated from protobuf enum openai.v1.OpenAIMessageRole
 */
export var OpenAIMessageRole;
(function (OpenAIMessageRole) {
    /**
     * OpenAI Message type is not Specified
     *
     * @generated from protobuf enum value: OPEN_AI_MESSAGE_ROLE_UNSPECIFIED = 0;
     */
    OpenAIMessageRole[OpenAIMessageRole["OPEN_AI_MESSAGE_ROLE_UNSPECIFIED"] = 0] = "OPEN_AI_MESSAGE_ROLE_UNSPECIFIED";
    /**
     * OpenAI System message
     *
     * @generated from protobuf enum value: OPEN_AI_MESSAGE_ROLE_SYSTEM = 1;
     */
    OpenAIMessageRole[OpenAIMessageRole["OPEN_AI_MESSAGE_ROLE_SYSTEM"] = 1] = "OPEN_AI_MESSAGE_ROLE_SYSTEM";
    /**
     * OpenAI User message
     *
     * @generated from protobuf enum value: OPEN_AI_MESSAGE_ROLE_USER = 2;
     */
    OpenAIMessageRole[OpenAIMessageRole["OPEN_AI_MESSAGE_ROLE_USER"] = 2] = "OPEN_AI_MESSAGE_ROLE_USER";
    /**
     * OpenAI Assistant message
     *
     * @generated from protobuf enum value: OPEN_AI_MESSAGE_ROLE_ASSISTANT = 3;
     */
    OpenAIMessageRole[OpenAIMessageRole["OPEN_AI_MESSAGE_ROLE_ASSISTANT"] = 3] = "OPEN_AI_MESSAGE_ROLE_ASSISTANT";
    /**
     * OpenAI Function message
     *
     * @generated from protobuf enum value: OPEN_AI_MESSAGE_ROLE_FUNCTION = 4;
     */
    OpenAIMessageRole[OpenAIMessageRole["OPEN_AI_MESSAGE_ROLE_FUNCTION"] = 4] = "OPEN_AI_MESSAGE_ROLE_FUNCTION";
})(OpenAIMessageRole || (OpenAIMessageRole = {}));
// @generated message type with reflection information, may provide speed optimized methods
class OpenAIFunctionCall$Type extends MessageType {
    constructor() {
        super("openai.v1.OpenAIFunctionCall", [
            { no: 1, name: "arguments", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "name", kind: "scalar", T: 9 /*ScalarType.STRING*/ }
        ]);
    }
    create(value) {
        const message = { arguments: "", name: "" };
        globalThis.Object.defineProperty(message, MESSAGE_TYPE, { enumerable: false, value: this });
        if (value !== undefined)
            reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string arguments */ 1:
                    message.arguments = reader.string();
                    break;
                case /* string name */ 2:
                    message.name = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string arguments = 1; */
        if (message.arguments !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.arguments);
        /* string name = 2; */
        if (message.name !== "")
            writer.tag(2, WireType.LengthDelimited).string(message.name);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message openai.v1.OpenAIFunctionCall
 */
export const OpenAIFunctionCall = new OpenAIFunctionCall$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OpenAIMessage$Type extends MessageType {
    constructor() {
        super("openai.v1.OpenAIMessage", [
            { no: 1, name: "content", kind: "scalar", opt: true, T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "role", kind: "enum", T: () => ["openai.v1.OpenAIMessageRole", OpenAIMessageRole] },
            { no: 3, name: "name", kind: "scalar", opt: true, T: 9 /*ScalarType.STRING*/ },
            { no: 4, name: "function_call", kind: "message", T: () => OpenAIFunctionCall }
        ]);
    }
    create(value) {
        const message = { role: 0 };
        globalThis.Object.defineProperty(message, MESSAGE_TYPE, { enumerable: false, value: this });
        if (value !== undefined)
            reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* optional string content */ 1:
                    message.content = reader.string();
                    break;
                case /* openai.v1.OpenAIMessageRole role */ 2:
                    message.role = reader.int32();
                    break;
                case /* optional string name */ 3:
                    message.name = reader.string();
                    break;
                case /* optional openai.v1.OpenAIFunctionCall function_call */ 4:
                    message.functionCall = OpenAIFunctionCall.internalBinaryRead(reader, reader.uint32(), options, message.functionCall);
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* optional string content = 1; */
        if (message.content !== undefined)
            writer.tag(1, WireType.LengthDelimited).string(message.content);
        /* openai.v1.OpenAIMessageRole role = 2; */
        if (message.role !== 0)
            writer.tag(2, WireType.Varint).int32(message.role);
        /* optional string name = 3; */
        if (message.name !== undefined)
            writer.tag(3, WireType.LengthDelimited).string(message.name);
        /* optional openai.v1.OpenAIFunctionCall function_call = 4; */
        if (message.functionCall)
            OpenAIFunctionCall.internalBinaryWrite(message.functionCall, writer.tag(4, WireType.LengthDelimited).fork(), options).join();
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message openai.v1.OpenAIMessage
 */
export const OpenAIMessage = new OpenAIMessage$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OpenAIPromptRequest$Type extends MessageType {
    constructor() {
        super("openai.v1.OpenAIPromptRequest", [
            { no: 1, name: "model", kind: "enum", T: () => ["openai.v1.OpenAIModel", OpenAIModel] },
            { no: 2, name: "messages", kind: "message", repeat: 1 /*RepeatType.PACKED*/, T: () => OpenAIMessage },
            { no: 3, name: "temperature", kind: "scalar", opt: true, T: 2 /*ScalarType.FLOAT*/ },
            { no: 4, name: "top_p", kind: "scalar", opt: true, T: 2 /*ScalarType.FLOAT*/ },
            { no: 5, name: "max_tokens", kind: "scalar", opt: true, T: 13 /*ScalarType.UINT32*/ },
            { no: 6, name: "user_id", kind: "scalar", opt: true, T: 9 /*ScalarType.STRING*/ },
            { no: 7, name: "presence_penalty", kind: "scalar", opt: true, T: 2 /*ScalarType.FLOAT*/ },
            { no: 8, name: "frequency_penalty", kind: "scalar", opt: true, T: 2 /*ScalarType.FLOAT*/ }
        ]);
    }
    create(value) {
        const message = { model: 0, messages: [] };
        globalThis.Object.defineProperty(message, MESSAGE_TYPE, { enumerable: false, value: this });
        if (value !== undefined)
            reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* openai.v1.OpenAIModel model */ 1:
                    message.model = reader.int32();
                    break;
                case /* repeated openai.v1.OpenAIMessage messages */ 2:
                    message.messages.push(OpenAIMessage.internalBinaryRead(reader, reader.uint32(), options));
                    break;
                case /* optional float temperature */ 3:
                    message.temperature = reader.float();
                    break;
                case /* optional float top_p */ 4:
                    message.topP = reader.float();
                    break;
                case /* optional uint32 max_tokens */ 5:
                    message.maxTokens = reader.uint32();
                    break;
                case /* optional string user_id */ 6:
                    message.userId = reader.string();
                    break;
                case /* optional float presence_penalty */ 7:
                    message.presencePenalty = reader.float();
                    break;
                case /* optional float frequency_penalty */ 8:
                    message.frequencyPenalty = reader.float();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* openai.v1.OpenAIModel model = 1; */
        if (message.model !== 0)
            writer.tag(1, WireType.Varint).int32(message.model);
        /* repeated openai.v1.OpenAIMessage messages = 2; */
        for (let i = 0; i < message.messages.length; i++)
            OpenAIMessage.internalBinaryWrite(message.messages[i], writer.tag(2, WireType.LengthDelimited).fork(), options).join();
        /* optional float temperature = 3; */
        if (message.temperature !== undefined)
            writer.tag(3, WireType.Bit32).float(message.temperature);
        /* optional float top_p = 4; */
        if (message.topP !== undefined)
            writer.tag(4, WireType.Bit32).float(message.topP);
        /* optional uint32 max_tokens = 5; */
        if (message.maxTokens !== undefined)
            writer.tag(5, WireType.Varint).uint32(message.maxTokens);
        /* optional string user_id = 6; */
        if (message.userId !== undefined)
            writer.tag(6, WireType.LengthDelimited).string(message.userId);
        /* optional float presence_penalty = 7; */
        if (message.presencePenalty !== undefined)
            writer.tag(7, WireType.Bit32).float(message.presencePenalty);
        /* optional float frequency_penalty = 8; */
        if (message.frequencyPenalty !== undefined)
            writer.tag(8, WireType.Bit32).float(message.frequencyPenalty);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message openai.v1.OpenAIPromptRequest
 */
export const OpenAIPromptRequest = new OpenAIPromptRequest$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OpenAIPromptResponse$Type extends MessageType {
    constructor() {
        super("openai.v1.OpenAIPromptResponse", [
            { no: 1, name: "content", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "prompt_tokens", kind: "scalar", T: 13 /*ScalarType.UINT32*/ },
            { no: 3, name: "completion_tokens", kind: "scalar", T: 13 /*ScalarType.UINT32*/ },
            { no: 4, name: "total_tokens", kind: "scalar", T: 13 /*ScalarType.UINT32*/ }
        ]);
    }
    create(value) {
        const message = { content: "", promptTokens: 0, completionTokens: 0, totalTokens: 0 };
        globalThis.Object.defineProperty(message, MESSAGE_TYPE, { enumerable: false, value: this });
        if (value !== undefined)
            reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string content */ 1:
                    message.content = reader.string();
                    break;
                case /* uint32 prompt_tokens */ 2:
                    message.promptTokens = reader.uint32();
                    break;
                case /* uint32 completion_tokens */ 3:
                    message.completionTokens = reader.uint32();
                    break;
                case /* uint32 total_tokens */ 4:
                    message.totalTokens = reader.uint32();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string content = 1; */
        if (message.content !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.content);
        /* uint32 prompt_tokens = 2; */
        if (message.promptTokens !== 0)
            writer.tag(2, WireType.Varint).uint32(message.promptTokens);
        /* uint32 completion_tokens = 3; */
        if (message.completionTokens !== 0)
            writer.tag(3, WireType.Varint).uint32(message.completionTokens);
        /* uint32 total_tokens = 4; */
        if (message.totalTokens !== 0)
            writer.tag(4, WireType.Varint).uint32(message.totalTokens);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message openai.v1.OpenAIPromptResponse
 */
export const OpenAIPromptResponse = new OpenAIPromptResponse$Type();
// @generated message type with reflection information, may provide speed optimized methods
class OpenAIStreamResponse$Type extends MessageType {
    constructor() {
        super("openai.v1.OpenAIStreamResponse", [
            { no: 1, name: "content", kind: "scalar", T: 9 /*ScalarType.STRING*/ },
            { no: 2, name: "finish_reason", kind: "scalar", opt: true, T: 9 /*ScalarType.STRING*/ }
        ]);
    }
    create(value) {
        const message = { content: "" };
        globalThis.Object.defineProperty(message, MESSAGE_TYPE, { enumerable: false, value: this });
        if (value !== undefined)
            reflectionMergePartial(this, message, value);
        return message;
    }
    internalBinaryRead(reader, length, options, target) {
        let message = target ?? this.create(), end = reader.pos + length;
        while (reader.pos < end) {
            let [fieldNo, wireType] = reader.tag();
            switch (fieldNo) {
                case /* string content */ 1:
                    message.content = reader.string();
                    break;
                case /* optional string finish_reason */ 2:
                    message.finishReason = reader.string();
                    break;
                default:
                    let u = options.readUnknownField;
                    if (u === "throw")
                        throw new globalThis.Error(`Unknown field ${fieldNo} (wire type ${wireType}) for ${this.typeName}`);
                    let d = reader.skip(wireType);
                    if (u !== false)
                        (u === true ? UnknownFieldHandler.onRead : u)(this.typeName, message, fieldNo, wireType, d);
            }
        }
        return message;
    }
    internalBinaryWrite(message, writer, options) {
        /* string content = 1; */
        if (message.content !== "")
            writer.tag(1, WireType.LengthDelimited).string(message.content);
        /* optional string finish_reason = 2; */
        if (message.finishReason !== undefined)
            writer.tag(2, WireType.LengthDelimited).string(message.finishReason);
        let u = options.writeUnknownFields;
        if (u !== false)
            (u == true ? UnknownFieldHandler.onWrite : u)(this.typeName, message, writer);
        return writer;
    }
}
/**
 * @generated MessageType for protobuf message openai.v1.OpenAIStreamResponse
 */
export const OpenAIStreamResponse = new OpenAIStreamResponse$Type();
/**
 * @generated ServiceType for protobuf service openai.v1.OpenAIService
 */
export const OpenAIService = new ServiceType("openai.v1.OpenAIService", [
    { name: "OpenAIPrompt", options: {}, I: OpenAIPromptRequest, O: OpenAIPromptResponse },
    { name: "OpenAIStream", serverStreaming: true, options: {}, I: OpenAIPromptRequest, O: OpenAIStreamResponse }
]);
