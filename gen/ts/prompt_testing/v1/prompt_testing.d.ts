// @generated by protobuf-ts 2.9.1 with parameter generate_dependencies,long_type_string,output_javascript_es2020,server_grpc1,force_client_none
// @generated from protobuf file "prompt_testing/v1/prompt_testing.proto" (package "prompt_testing.v1", syntax proto3)
// tslint:disable
import { MessageType } from "@protobuf-ts/runtime";
/**
 * A request for a prompt - sending user input to the server.
 *
 * @generated from protobuf message prompt_testing.v1.PromptTestRequest
 */
export interface PromptTestRequest {
    /**
     * The application ID
     *
     * @generated from protobuf field: string application_id = 1;
     */
    applicationId: string;
    /**
     * The project ID
     *
     * @generated from protobuf field: optional string prompt_config_id = 2;
     */
    promptConfigId?: string;
    /**
     * The model vendor, for example "OPEN_AI"
     *
     * @generated from protobuf field: string model_vendor = 3;
     */
    modelVendor: string;
    /**
     * The model type to use, for example "gpt-3.5-turbo"
     *
     * @generated from protobuf field: string model_type = 4;
     */
    modelType: string;
    /**
     * A serialized JSON object containing the model parameters
     *
     * @generated from protobuf field: bytes model_parameters = 5;
     */
    modelParameters: Uint8Array;
    /**
     * A serialized JSON array of provider message objects
     *
     * @generated from protobuf field: bytes provider_prompt_messages = 6;
     */
    providerPromptMessages: Uint8Array;
    /**
     * The User prompt variables
     * This is a hash-map of variables that should have the same keys as those contained by the PromptConfigResponse
     *
     * @generated from protobuf field: bytes template_variables = 7;
     */
    templateVariables: Uint8Array;
}
/**
 * An Streaming Prompt Response Message
 *
 * @generated from protobuf message prompt_testing.v1.PromptTestingStreamingPromptResponse
 */
export interface PromptTestingStreamingPromptResponse {
    /**
     * Prompt Content
     *
     * @generated from protobuf field: string content = 1;
     */
    content: string;
    /**
     * Finish reason, given when the stream ends
     *
     * @generated from protobuf field: optional string finish_reason = 2;
     */
    finishReason?: string;
    /**
     * Number of tokens used for the prompt request, given when the stream ends
     *
     * @generated from protobuf field: optional uint32 request_tokens = 3;
     */
    requestTokens?: number;
    /**
     * Number of tokens used for the prompt response, given when the stream ends
     *
     * @generated from protobuf field: optional uint32 response_tokens = 4;
     */
    responseTokens?: number;
    /**
     * Stream duration, given when the stream ends
     *
     * @generated from protobuf field: optional uint32 stream_duration = 5;
     */
    streamDuration?: number;
    /**
     * An error message, if an error occurs
     *
     * @generated from protobuf field: optional string error_message = 6;
     */
    errorMessage?: string;
    /**
     * The test record ID, given when the stream ends
     *
     * @generated from protobuf field: optional string prompt_test_record_id = 7;
     */
    promptTestRecordId?: string;
}
declare class PromptTestRequest$Type extends MessageType<PromptTestRequest> {
    constructor();
}
/**
 * @generated MessageType for protobuf message prompt_testing.v1.PromptTestRequest
 */
export declare const PromptTestRequest: PromptTestRequest$Type;
declare class PromptTestingStreamingPromptResponse$Type extends MessageType<PromptTestingStreamingPromptResponse> {
    constructor();
}
/**
 * @generated MessageType for protobuf message prompt_testing.v1.PromptTestingStreamingPromptResponse
 */
export declare const PromptTestingStreamingPromptResponse: PromptTestingStreamingPromptResponse$Type;
/**
 * @generated ServiceType for protobuf service prompt_testing.v1.PromptTestingService
 */
export declare const PromptTestingService: any;
export {};
